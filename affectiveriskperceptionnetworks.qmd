---
title: "Affective Risk Perception Networks"
author: "Jan-Erik Johanson, Alisa Puustinen & Oliver Saal"
subtitle: "Draft article for ÅAU Sociology summer seminar 1-2 June 2023"
abstract: |
  This is an early draft version on a research project I, senior researcher Alisa Puustinen
  at Pelastusopisto and professor Jan-Erik Anderson at University of Tampere have been working
  on. Its main point is to argue for a network conception of risk perception, i.e., that
  individuals' perceptions of hazards and risks are constructed through a complex system of
  interactions, as opposed to direct perception and evaluation of singular risk events.
  
  We recently decided to divide the paper into two: one empirical section for a journal,
  and one theoretical discussion for an invited book chapter.
  The formatting is still very all-over-the-place, I apologize for any illegible graphics!
  
  A legible online version is temporarily available at my website:
    
  osaal.github.io/affectiveriskperceptionnetworks
date: last-modified
date-format: long
---

```{r article-setup, include=FALSE}
# Clear environment and save parameters to avoid clashes with previous work
rm(list=ls())
resetpar <- par(no.readonly = TRUE)
# Setup article work directories and libraries
workdir <- "C:/Users/olive/RPROJS/papers/affectiveriskperceptionnetworks"
packages <- c("tidyverse", "naniar", "knitr", "ggstatsplot", "bootnet", "ppcor", "smacof", "qgraph", "NetworkComparisonTest")
lapply(packages, library, character.only=TRUE)
setwd(workdir)

set.seed(12345)
```

# Introduction {#sec-introduction}

# Previous Research and Theory {#sec-previous}

## A Preliminary Definition of Risk, Risk Perception, and Resilience

The usage of the three key words (risk, risk perception, and resilience) in the research literature is varied. Some attempts have been made at collating these divergent definitions, notably by Aven [-@aven2022]. They present six distinct perspectives, roughly named the disjunct, broader disjunct, event, consequence, undesirable potentials, and combination perspectives. Depending on the perspective, risks are defined variably as reduction in functionality, events, consequences, and/or uncertainties related to consequences. Similarly, resilience is variably defined as recovering ability, reaction ability, or even not defined at all [@aven2022].

The problems with most of these perspectives, according to Aven [-@aven2022], is that they distinctly draw lines between risks and resilience. Particularly in the two disjunct perspectives as well as the event perspective, the risk ends once the event is declared over and the recovery phase as begun - the two stages are incommensurable.

## Risk and Systems

Perceptions of flood risk in particular have been found to correlate with perceptions of other technological risks [@zhai2008].

It is important to distinguish between the ontology and the perception of risks. The former refers to the contents, dynamics, and structure of the risk itself, while the latter refers to individual's meaning-makings of risks.

In the space of risk ontology, research has suggested that risks can be divided into global systemic risks (GSR) and conventional risks [@renn2019; @renn2021; @renn2022]. Summarily, GSR's transgress traditional social and scientific boundaries, are intertwined and interconnected with one another, present non-linear causality in their structure, and have non-deterministic effects [@haas2022].

Non-deterministic effects cannot be adequately reduced to deterministic models.

However, risk ontology is not the same as risk perception.

## Risk Perception

Risk perception has been widely studied in the past two decades, but is still lacking a coherent theoretical framework [@kellens2013]. Generally speaking, perception has been found to be related to both hazard experiences and reactive behaviour.

Perception is related to behaviour in some way, but the causal connection is unclear [@dekoning2017]. It has been shown that post-event risk decision-making is drastically reactive to the event [@slovic2004; @gallagher2014]. The time after event is also very relevant, with post-event risk perception not only falling, but falling at a speed derivative of the time post-event [@atreya2013; @bin2013; @gallagher2014]. One study found that storm risk perception drops below objective risk probabilities given enough time between events, but rises rapidly upon the following event [@magliocca2018].

## Experiences and Perception

The previous literature generally distinguishes between two types of experience: **direct** and **near-miss** experiences. Direct experiences are, as the name implies, directly and non-mediately experienced, while near-miss experiences are situations that could have resulted in the expression of the hazard event, but did not. As an example, a direct experience of a fire could be a stove fire in the individual's kitchen, while a near-miss experience of a fire could be a situation where the individual noticed that they had left flammable materials on an active stove-top, but managed to remove the materials prior to them catching fire.

However, we propose that risk experiences are much more varied than this. We suggest five distinct forms, borrowed from and inspired by inter-group contact theory [ICT, @zhou2020].

1.  Direct non-intensive experience
2.  Direct intensive experience
3.  Extended experience
4.  Imagined experience
5.  Mediated experience

The first two experiences represent the regular direct experience, with a clear distinction: the intensity in the experience is much greater in type (2) than in type (1). Burning food on the stove-top is an example of a direct non-intensive experience, while surviving a house fire is a direct intensive experience.[^1]

[^1]: This distinction already suggests that the underlying function is a linear spectrum from low to high intensity. This thought needs to be further developed.

If extended contact in ICT is "knowing that another ingroup member has at least one cross-group friend" [@zhou2020 p. 9], then extended risk experiences is knowing that a significant other has experienced the hazard event in question.

Imagined experience represents near misses, but with an emphasis on the imaginative part. In this perspective, the causally empowered aspect is not how the experience is 'almost like a risk' (i.e., risk resemblance), but the near-miss as a trigger for considering a potential risk realisation. In other words: the near-miss triggers the individual to consider what the risk could have looked like and how it could have played out, which itself triggers a reconsideration of the probabilities attached to the risk event.

Mediated experience is the experiencing the risk as portrayed in media [cf. @zhou2020 p. 15]. This differs from the extended experience in that the originator of the message is not a significant other of the individual. Risks are experienced mediated all the time: from COVID-19 discussions on social media to news events of the war in Ukraine, individuals are constantly exposed to mediated experiences. In risk perception research, this topic has been studied under the sub-topic of risk communication studies.

One motivation for using these distinctive forms of experience may be drawn from social phenomenology.

-   The base world of work and the doxic position [@heidegger1962 p. (56-57); @schütz1962 p. 227; @bégout2007].
-   Action oriented towards goals or projects [@schütz1967 p. 59-64; @heidegger1962 p. (145)].
-   Ideal-typical projection requires familiarity and typicality [@schütz2011 p. 126-128].
-   Recognition of familiarity/typicality occurs through relevance systems: topical, interpretational, and motivational relevance [@schütz2011 p. 94-95, 108, 113, 119].

# Hypotheses {#sec-hypotheses}

There are two main findings in the previous literature:

1.  Direct hazard experiences lead to a decrease in perception of risk probability.
2.  Near-miss hazard experiences lead to an increase in perception of risk probability.

To investigate the support for these findings, we apply network analysis. Because networks can be analysed on both system and node levels, we thus divide each finding into two distinct propositions:

1.  Direct hazard experiences lead to a decrease in perception of risk probability on the:
    1.  System level, and the
    2.  Node level.
2.  Near-miss hazard experiences lead to an increase in perception of risk probability on the:
    1.  System level, and the
    2.  Node level.

The system level test cannot distinguish between different objects of perception, as we are testing a whole network composed of multiple modes. Thus, the system level test judges a more general causality: that the experience (whether near-miss or direct) causally affects the system of risk perception.

The system- and node-level hypotheses are independent. Because of the complex causal mechanisms of networks, the cumulative effects on the system level of any given input need not match up with a singular node-level effect. Just because the risk perception network changes does not automatically mean that a particular node changes, and vice versa. Whether a node affects system structure or system changes affect singular nodes is dependent on the relations between nodes within the system. As an example of this: networks have two structural properties that researchers can compare using psychometric network tools, global strength and network variance. Global strength simply refers to the sum of the absolute node connection weights in the network, while network variance refers to changes in *any* connection weight. As van Borkulo and colleagues [-@vanborkulo2022] show, either measure can vary independently of the other given certain change configurations between compared networks.

In a similar vein, we suggest that the risk perception network and its constituent nodes may vary independently, giving rise to potential difference in structural and constituent effects. Thus, we divide the hypotheses into two categories.

Further, we introduce a proxy variable measuring direct effect, whether an individual works in the emergency services.

Thus, we have two groups with three hypotheses each:

1.  System level:
    1.  Experiencing a fire leads to a sparser risk perception network
    2.  Experiencing a near-miss leads to a denser risk perception network
    3.  Working in emergency services leads to a sparser risk perception network
2.  Node level:
    1.  Experiencing a fire leads to a decrease in the centrality of fire in the risk perception network
    2.  Experiencing a near-miss leads to an increase in the centrality of fire in the risk perception network
    3.  Working in emergency services leads to a decrease in the the centrality of fire in the risk perception network

# Materials and Methods {#sec-materialsandmethods}

## Materials {#sec-materials}

### Data Collection {#sec-datacollection}

```{r data-import}
# Import raw data
rawdata <- tibble(read.csv2("emergencyservicesattitudes2023.csv"))
```

We used the Finnish Emergency Services Attitudes 2023 material, consisting of N = 3055 survey respondents. The survey was collected between 17 January and 2 February 2023 as an on-line panel study, with sampling corresponding to central geographical, gender, and age distributions of the mainland Finnish population aged 18-79 years. Participation was voluntary and informed consent was retrieved.

### Dependent Variables {#sec-dependentvariables}

**Comment: Move descriptive statistics into Results?**

In the survey, respondents were asked to gauge the probability that they would encounter any of fourteen listed risks or threats in their personal lives. The risks are listed below, with short-hand names in brackets.

-   "Extreme weather phenomena (flood, drought, storm etc.)" \[Weather\]
-   "Traffic accident" \[Traffic\]
-   "Fire" \[Fire\]
-   "Nuclear power plant disaster" \[Nuclear\]
-   "Workplace accident" \[Work\]
-   "Leisure-time accident (at home/at hobbies etc.)" \[Leisure\]
-   "Attack with weapons directed at the Finnish state" \[War\]
-   "Great environmental accident, such as an oil catastrophe" \[Environmental\]
-   "Dangerous transmittable disease, pandemic" \[Pandemic\]
-   "Illness, severely falling ill (e.g., life-threatening cancer)" \[Illness\]
-   "Act of violence" \[Violence\]
-   "Operational failure directed at e.g., electrical, water, or food supply, information traffic or the informational system" \[Operational\]
-   "Influencing through information, fake news, other so-called hybrid threats" \[Hybrid\]
-   "Growth of tensions between social groups, polarization" \[Polarization\]

For each variable, respondents judged their perceived subjective probability on a four-point scale as *very probable*, *somewhat probable*, *somewhat improbable*, *very improbable* and *cannot say*. These variables are later referred to as *risk perception variables*. Excluding the uncertain responses as missing values, the distributions are presented in @fig-dependents.

```{r}
#| label: fig-dependents
#| fig-cap: "Distributions of risk perception variables"
#| fig-subcap: 
#| -  Weather
#| -  Traffic
#| -  Fire
#| -  Nuclear
#| -  Work
#| -  Leisure
#| -  War
#| -  Environmental
#| -  Pandemic
#| -  Illness
#| -  Violence
#| -  Operational
#| -  Hybrid
#| -  Polarization
#| layout-ncol: 3

data <- rawdata %>%
  dplyr::select(question_3_row_1:question_3_row_14)

data <- data %>%
  rename(Weather = question_3_row_1,
         Traffic = question_3_row_2,
         Fire = question_3_row_3,
         Nuclear = question_3_row_4,
         Work = question_3_row_5,
         Leisure = question_3_row_6,
         War = question_3_row_7,
         Environmental = question_3_row_8,
         Pandemic = question_3_row_9,
         Illness = question_3_row_10,
         Violence = question_3_row_11,
         Operational = question_3_row_12,
         Hybrid = question_3_row_13,
         Polarization = question_3_row_14)

data <- replace_with_na_all(
  data,
  condition = ~.x == 5)

ggplot(data) + geom_bar(aes(x = Weather)) + coord_cartesian(ylim=c(0,3055))
ggplot(data) + geom_bar(aes(x = Traffic)) + coord_cartesian(ylim=c(0,3055))
ggplot(data) + geom_bar(aes(x = Fire)) + coord_cartesian(ylim=c(0,3055))
ggplot(data) + geom_bar(aes(x = Nuclear)) + coord_cartesian(ylim=c(0,3055))
ggplot(data) + geom_bar(aes(x = Work)) + coord_cartesian(ylim=c(0,3055))
ggplot(data) + geom_bar(aes(x = Leisure)) + coord_cartesian(ylim=c(0,3055))
ggplot(data) + geom_bar(aes(x = War)) + coord_cartesian(ylim=c(0,3055))
ggplot(data) + geom_bar(aes(x = Environmental)) + coord_cartesian(ylim=c(0,3055))
ggplot(data) + geom_bar(aes(x = Pandemic)) + coord_cartesian(ylim=c(0,3055))
ggplot(data) + geom_bar(aes(x = Illness)) + coord_cartesian(ylim=c(0,3055))
ggplot(data) + geom_bar(aes(x = Violence)) + coord_cartesian(ylim=c(0,3055))
ggplot(data) + geom_bar(aes(x = Operational)) + coord_cartesian(ylim=c(0,3055))
ggplot(data) + geom_bar(aes(x = Hybrid)) + coord_cartesian(ylim=c(0,3055))
ggplot(data) + geom_bar(aes(x = Polarization)) + coord_cartesian(ylim=c(0,3055))
```

The risks judged to be most likely on average were pandemics, illnesses, and hybrid threats. The least likely experiences were nuclear power plant disasters, wars against Finland, and workplace accidents. Judging from missing values, respondents were most certain about the probability of experiencing extreme weather phenomena, and least certain about workplace accidents (@fig-na-analysis).

```{r}
#| label: fig-na-analysis
#| fig-cap: "Missing values by variable"

vis_miss(data)
```

### Control Variables {#sec-controlvariables}

**Comment: Remove gender, age and degree of urbanisation completely? Only used to check that data represents general population, not used in main analysis!**

We used three substantive control variables:

-   Direct experience of fire
-   Near miss-experience of fire
-   Emergency services employment

Respondents were asked whether they had had a direct experience of a fire in the past twelve months. They were similarly asked whether they had experienced a near-miss situation, i.e., a scenario that could have ended in a fire but did not. Finally, the respondents were asked whether they work in the emergency services in any capacity. These three variables constitute our substantive control variables, and operationalise three distinct hypotheses (see @sec-hypotheses) regarding the network structure. Their descriptive statistics are presented in @fig-substantive-desc.

```{r}
#| label: fig-substantive-desc
#| fig-cap: "Substantive Control Variables"
#| fig-subcap: 
#|   - "Direct Experience of Fire"
#|   - "Near-Miss Experience of Fire"
#|   - "Emergency Services Employment"
#| layout: [[1, 1], [1, -1]]
#| cache: true

data <- rawdata %>%
  dplyr::select(question_39_row_1:question_41_row_1) %>%
  rename(Direct = question_39_row_1,
         Near.Miss = question_40,
         EMS = question_41_row_1) %>%
  bind_cols(data, .)

data$Direct <- case_match(
  data$Direct,
  1 ~ 1,
  2 ~ 0,
  3 ~ NA,
  .default = NA
)
data$Near.Miss <- case_match(
  data$Near.Miss,
  1 ~ 1,
  2 ~ 0,
  3 ~ NA,
  .default = NA
)
data$EMS <- case_match(
  data$EMS,
  1 ~ 1,
  2 ~ 0,
  3 ~ NA,
  .default = NA
)

subsdata <- tibble(
    "Direct" = factor(
      data$Direct,
      levels = c(0:1),
      labels = c("No", "Yes")
    ),
    "Near.Miss" = factor(
      data$Near.Miss,
      levels = c(0:1),
      labels = c("No", "Yes")
    ),
    "EMS" = factor(
      data$EMS,
      levels = c(0:1),
      labels = c("No", "Yes")
    )
  )

ggplot(subsdata) + geom_bar(aes(x = Direct))
ggplot(subsdata) + geom_bar(aes(x = Near.Miss))
ggplot(subsdata) + geom_bar(aes(x = EMS))
```

## Methods {#sec-methods}

All analyses were completed in RStudio version 2023.03.0 build 386 [@positteam2023]. Data were processed using the `tidyverse` [@wickham2019] and `naniar` [@tierney2023] packages. Plots and graphs were generated in `ggplot2` [@wickham2016], including the `ggstatsplot` [@patil2021] extension package. MDS rotations were done in `smacof` [@mair2022] and partial correlations with `ppcor` [@kim2015]. Network comparison was conducted in `NetworkComparisonTest` [@vanborkulo2022]. Network graphs and related plotting and statistics were conducted in `bootnet` [@epskamp2018b] and `qgraph` [@epskamp2012]. The article was written in RMarkdown and compiled using the `knitr` [@xie2014; @xie2015; @xie2023] package for reproducibility.

We started by fitting a model for the graphical representation of networks. We modelled a partial correlation network of the risk perception variables using the multidimensional scaling (MDS) technique [@jones2018]. We thus retrieved Shepard curves for each MDS type and chose model type by balancing parsimony with increasing fit (reduction of the stress factor, see [@jones2018]). This model was only used to construct the MDS model.

For the main analysis, we fitted a pairwise Markov random field (PMRF) model as a Gaussian graphical model (GGM). We used Spearman correlations and the EBICglasso estimator function [@epskamp2012; @foygel2010]. We fitted two models: a non-parametric model and a case-dropping network model. The former was used for presenting and analysing the network as a graph and as a plot of centrality indices, and the latter was used for analysing the stability of centrality indices on both system- and node levels [@epskamp2018b].

**Comment: Add more description here, especially in how to interpret CS coefficients and bootstrapped centrality measures.**

To compare between groups, we estimated group-wise Gaussian graphical models and used the network comparison test (NCT) as outlined by Fried, Epskamp, Veerman and van Borkulo [-@fried2022].

# Results {#sec-results}

## Network Estimation and Robustness {#sec-networkestimation}

We first started by estimating the network model using the `EBICglasso` algorithm.

```{r}
#| label: model-estimation

# Estimate the network. Change "nCores" to a fitting amount of processor cores.
network <- estimateNetwork(
  dplyr::select(data, Weather:Polarization),
  default = "EBICglasso",
  corMethod = "cor",
  corArgs = list(method = "spearman"),
  nonPositiveDefinite = "continue"
)
```

To graphically plot the network, we modelled the resulting network using the MDS method. Shepard plots (@fig-mds-shepards) suggested that we use the spline model.

```{r}
#| label: fig-mds-shepards
#| fig-cap: "Shepard stress plots of MDS configurations"
#| fig-subcap: 
#| -  "Ordinal"
#| -  "Interval"
#| -  "Ratio"
#| -  "Spline"
#| layout-ncol: 2

dis <- sim2diss(network$graph)
mds_ordinal <- mds(dis, type = "ordinal")
mds_interval <- mds(dis, type = "interval")
mds_ratio <- mds(dis, type = "ratio")
mds_spline <- mds(dis, type = "mspline")

plot(mds_ordinal,
     plot.type="Shepard",
     sub = paste0("Stress = ", round(mds_ordinal$stress, 2)))
plot(mds_interval,
     plot.type="Shepard",
     sub = paste0("Stress = ", round(mds_interval$stress, 2)))
plot(mds_ratio,
     plot.type="Shepard",
     sub = paste0("Stress = ", round(mds_ratio$stress, 2)))
plot(mds_spline,
     plot.type="Shepard",
     sub = paste0("Stress = ", round(mds_spline$stress, 2)))
```

**Comment: Check that Spearman and polychoric produces the same result (when matrix is definite positive).**

We then retrieved a robust model of the graph using the `bootnet` package [@epskamp2018b]. The model uses the `EBICglasso` algorithm, which searches for the model that locally minimises the extended Bayesian Information Criterion [@epskamp2018b; @foygel2010]. The estimation is done using Spearman correlations because our data are expected non-normally distributed. While polychoric correlations would be possible, the small sample sizes in sub-population comparison may result in a non-positive definite correlation matrix, which disables analysis. We retrieved both non-parametric and case-dropping networks for analysis.

```{r}
#| label: bootstraps

# Run the following only once if possible, as they take time to run
# Completed in 4 min 20 s. on AMD Ryzen 9 5900HS with nCores = 16

bootstrap <- bootnet(
  dplyr::select(data, Weather:Polarization),
  nBoots     = 1000,
  default    = "EBICglasso",
  type       = "nonparametric",
  nCores     = 16,               # Change to appropriate processor core count
  statistics = c("edge",
                 "strength",
                 "closeness",
                 "betweenness",
                 "expectedInfluence"
                 ),
  verbose    = TRUE,
  corMethod = "cor",
  corArgs = list(method = "spearman")
)

# Completed in 4 min 10 s. on AMD Ryzen 9 5900HS with nCores = 16
casedrop <- bootnet(
  dplyr::select(data, Weather:Polarization),
  nBoots     = 1000,
  default    = "EBICglasso",
  type       = "case",
  nCores     = 16,               # Change to appropriate processor core count
  statistics = c("edge",
                 "strength",
                 "closeness",
                 "betweenness",
                 "expectedInfluence"
                 ),
  verbose    = TRUE,
  corMethod = "cor",
  corArgs = list(method = "spearman")
)

stability <- corStability(casedrop, verbose = FALSE)
```

The robust network is plotted using the two-dimensional MDS solution as its layout, enabling us to interpret graphical distance as a proxy for vertex strength. @fig-bootstrapped-model-1 shows the network graph.

```{r}
#| label: fig-bootstrapped-model-1
#| fig-cap: "Bootstrapped network. Edge labels indicate partial correlation strength."

# Plot network graph with previously configured layout
plot(
  bootstrap$sample,
  layout = mds_spline$conf,
  edge.labels = TRUE,
)
```

```{r}
#| label: tbl-network-stats
#| tbl-cap: "Descriptive statistics of network nodes"
summary <- tibble(
  Node = rownames(network$graph),
  Max = summarise(as_tibble(network$graph), across(everything(), max)) %>% unlist(., use.names=FALSE),
  Min = summarise(as_tibble(network$graph), across(everything(), min)) %>% unlist(., use.names=FALSE),
  Mean = summarise(as_tibble(network$graph), across(everything(), mean)) %>% unlist(., use.names=FALSE),
  SD = summarise(as_tibble(network$graph), across(everything(), sd)) %>% unlist(., use.names=FALSE)
)

cent <- centralityTable(network$graph, standardized = FALSE) %>%
  reshape2::dcast(
    node ~ measure,
    value.var = "value"
  ) %>%
  rename(
    Node = "node"
  )

summary <- left_join(summary, cent, by = "Node")

kable(
  summary,
  digits = 2,
  col.names = c("Node", "Maximum", "Minimum", "Mean", "SD", "Betweenness", "Closeness", "Strength", "Expected Influence")
  )
```

There are two distinct connections in the network: Traffic-Fire (`r round(network$graph[2,3], 2)`) and Hybrid-Polarization (`r round(network$graph[13,14], 2)`). Most other connections are fairly weak, with low-to-medium partial correlations.

The strongest connections are between Traffic and Fire (strength = `r round(as.numeric(summary[2, "Max"]), 2)`). Most nodes have only positive connections, with nuclear, work, illness, and hybrid being the only nodes with connections below zero. Mean connection strength is low across most nodes, but variation among nodes is comparatively high.

Four node connections are negative: Fire-Hybrid (`r round(network$graph["Fire","Hybrid"], 2)`), Nuclear-Hybrid (`r round(network$graph["Nuclear","Hybrid"], 2)`), Work-Illness (`r round(network$graph["Work","Illness"], 2)`), and Hybrid-Work (`r round(network$graph["Hybrid","Work"], 2)`).

@fig-bootstrapped-model-2 shows node centrality measures by node and measure. Strength varies between `r round(as.numeric(summary[1, "Strength"]), 1)` for extreme weather phenomena and `r round(as.numeric(summary[3, "Strength"]), 1)` for fire.

Closeness is very low, with every node around 0.005 in closeness. The similarity in scores suggests that nodes are fairly evenly connected.

Betweenness, however, is much more varied. Weather presents a betweenness of zero, meaning that it does not feature in any shortest path connection in the network. At the other end, Environmental and Illness feature in fourteen shortest paths, thus being very central nodes in the network.

As there are very few negative connections, expected influence mirrors strength for most nodes. Fire, Nuclear, Work, Illness, Operational, and Hybrid present at least one negative connection, which results in their expected influence being slightly lower than their strength.

@tbl-sml shows the smallworldness statistics for the network. The smallworldness index is not substantially larger than either 1 or 3, suggesting that the network is not a small-world network [@humphries2008; @newman2003]. Neither transitivity nor average path length (APL) is substantially higher than their randomly generated counterparts, further suggesting that the network is not considered a small-world network.

```{r}
#| label: tbl-sml
#| tbl-cap: "Smallworldness statistics of bootstrapped network, 1000 permutations for random networks"

sml <- as_tibble(as.list(smallworldness(network$graph)))
sml <- round(sml, digits = 3)

sml <- unite(
  sml,
  col="transCI",
  c("trans_rnd_lo", "trans_rnd_up"),
  sep="-"
)
sml <- unite(
  sml,
  col="averagelengthCI",
  c("averagelength_rnd_lo", "averagelength_rnd_up"),
  sep="-"
)
sml$transCI <- paste0("(",sml$transCI,")")
sml$averagelengthCI <- paste0("(",sml$averagelengthCI,")")

sml <- unite(
  sml,
  col="trans_rnd",
  c("trans_rnd_M", "transCI"),
  sep=" "
)
sml <- unite(
  sml,
  col="averagelength_rnd",
  c("averagelength_rnd_M", "averagelengthCI"),
  sep=" "
)

kable(
  sml,
  digits = 3,
  col.names = c("Smallworldness Index", "Transitivity", "APL", "Random transitivity (95% CI)", "Random APL (95% CI)")
)
```

```{r}
#| label: fig-bootstrapped-model-2
#| fig-cap: "Centrality measures of bootstrapped network, raw scores."

# Plot centrality data
centralityPlot(
  bootstrap$sample,
  include = "All"
  )
```

The case-dropped models can be correlated with the original model to estimate how well the case-dropped model centrality measures represent the original. The *correlation stability coefficient* (CS coefficient) then determines the proportion of cases that may be dropped whilst still retaining a correlation of $r = p$, where $p$ is the preferred correlational level, in $(1-\alpha)/100$ % of cases. For this study, we use the default values of $r = 0.7$ and $95$ per cent.

Previous research suggests that, when interpreting differences between centralities (e.g., if one risk perception is more central to the network than another), the centrality stability coefficient should preferably be above 0.5, with higher equalling a more stable centrality measure [@epskamp2018b; @fried2022].

@fig-bootstrapped-model-3 shows the stability of the centrality measures when case-dropping. The CS coefficients are listed in @tbl-cscoef. Strength, closeness and expected influence are all stable, with up to 75 per cent of cases having to be dropped before the correlation drops below 0.7 in 95% of bootstraps. However, betweenness does not seem to be stable enough to interpret, at a CS coefficient of only `r round(stability[["betweenness"]], 2)`.

| Measure            | CS coefficient                                 |
|--------------------|------------------------------------------------|
| Betweenness        | `r round(stability[["betweenness"]], 2)`       |
| Closeness          | `r round(stability[["closeness"]], 2)`         |
| Expected Influence | `r round(stability[["expectedInfluence"]], 2)` |
| Strength           | `r round(stability[["strength"]], 2)`          |

: Correlation Stability (CS) coefficients of the bootstrapped model {#tbl-cscoef}

```{r}
#| label: fig-bootstrapped-model-3
#| fig-cap: "Stability plot"

# Plot stability tests
plot(casedrop, statistics = "all") +
  geom_hline(yintercept = 0.7, color = "grey", linetype = "dashed")
```

@fig-bootstrapped-model-4 shows significance tests of the differences in connection strengths between each node-pair vertex, ordered by connection strength in the original estimated network. In other words, we tested whether two connections significantly differ from each other at $\alpha = 0.05$. Around half of the comparisons are significant. The Work-Illness vertex is significantly different from every other vertex. Traffic-Fire and Hybrid-Polarization are both significantly different from all other vertices except from each other.

```{r}
#| label: fig-bootstrapped-model-4
#| fig-cap: "Connection pair-wise significance tests. Diagonal shows strength of original connection, gray boxes indicate non-significant differences, black boxes indicate significant differences at 0.05."

# Plot bootstrapped significance intervals
plot(
  bootstrap,
  statistics          = "edge",
  plot                = "difference",
  alpha               = 0.05,
  onlyNonZero         = TRUE,
  order               = "mean"
)
```

## Network Comparisons {#sec-networkcomparisons}

```{r}
#| label: network-setup

# Estimate networks for every subgroup separately
net_direct_0 <- data %>%
  dplyr::filter(Direct == 0) %>%
  dplyr::select(Weather:Polarization) %>%
  estimateNetwork(
    default = "EBICglasso",
    corMethod = "cor",
    corArgs = list(method = "spearman"),
    verbose = FALSE,
    nonPositiveDefinite = "continue"
  )
net_direct_1 <- data %>%
  dplyr::filter(Direct == 1) %>%
  dplyr::select(Weather:Polarization) %>%
  estimateNetwork(
    default = "EBICglasso",
    corMethod = "cor",
    corArgs = list(method = "spearman"),
    verbose = FALSE,
    nonPositiveDefinite = "continue"
  )

net_nearmiss_0 <- data %>%
  dplyr::filter(Near.Miss == 0) %>%
  dplyr::select(Weather:Polarization) %>%
  estimateNetwork(
    default = "EBICglasso",
    corMethod = "cor",
    corArgs = list(method = "spearman"),
    verbose = FALSE,
    nonPositiveDefinite = "continue"
  )
net_nearmiss_1 <- data %>%
  dplyr::filter(Near.Miss == 1) %>%
  dplyr::select(Weather:Polarization) %>%
  estimateNetwork(
    default = "EBICglasso",
    corMethod = "cor",
    corArgs = list(method = "spearman"),
    verbose = FALSE,
    nonPositiveDefinite = "continue"
  )

net_ems_0 <- data %>%
  dplyr::filter(EMS == 0) %>%
  dplyr::select(Weather:Polarization) %>%
  estimateNetwork(
    default = "EBICglasso",
    corMethod = "cor",
    corArgs = list(method = "spearman"),
    verbose = FALSE,
    nonPositiveDefinite = "continue"
  )
net_ems_1 <- data %>%
  dplyr::filter(EMS == 1) %>%
  dplyr::select(Weather:Polarization) %>%
  estimateNetwork(
    default = "EBICglasso",
    corMethod = "cor",
    corArgs = list(method = "spearman"),
    verbose = FALSE,
    nonPositiveDefinite = "continue"
  )
```

We compared networks conditioned on the three substantive control variables (see @sec-controlvariables): Direct experience of fire, near miss-experience of fire, and emergency services employment. In each case, we expect a lower global density - reflecting the weakening of System II risk assessment in favour of System I. We further hypothesised that the node strength of fire experience would follow a unique development:

-   Experiencing a fire leads to higher probability (the salience hypothesis).
-   Experiencing a near-miss leads to lower probability (the false certainty hypothesis).
-   Working in emergency services leads to higher probability (the culture hypothesis).

The statistics are shown in @tbl-networkcomps. The networks are graphed in @fig-comp-graphs.

```{r}
#| label: networkcomps

# Compare strength between networks
# NB: Using pull request #32 of NCT for multi-core support
comp_direct <- NCT(
  net_direct_0,
  net_direct_1,
  gamma = 0.5,
  it = 1000,
  abs = TRUE,
  test.centrality = TRUE,
  centrality = c("closeness", "betweenness", "strength", "expectedInfluence"),
  nodes = "Fire",
  progressbar = FALSE,
  verbose = FALSE,
  nCores = 16,
  make.positive.definite = TRUE
)

comp_nearmiss <- NCT(
  net_nearmiss_0,
  net_nearmiss_1,
  gamma = 0.5,
  it = 1000,
  abs = TRUE,
  test.centrality = TRUE,
  centrality = c("closeness", "betweenness", "strength", "expectedInfluence"),
  nodes = "Fire",
  progressbar = FALSE,
  verbose = FALSE,
  nCores = 16,
  make.positive.definite = TRUE
)

comp_ems <- NCT(
  net_ems_0,
  net_ems_1,
  gamma = 0.5,
  it = 1000,
  abs = TRUE,
  test.centrality = TRUE,
  centrality = c("closeness", "betweenness", "strength", "expectedInfluence"),
  nodes = "Fire",
  progressbar = FALSE,
  verbose = FALSE,
  nCores = 16,
  make.positive.definite = TRUE
)
```

::: {#tbl-networkcomps layout-nrow="3"}
| Test               | Statistic                                                      | Significance                                      |
|----------------|-------------------------------|-------------------------|
| Network variance   | $\Delta_{O} =$ `r round(comp_direct$nwinv.real, 2)`            | $p =$ `r round(comp_direct$nwinv.pval, 4)`        |
| Global strength    | $\Delta_{S}^{g} =$ `r round(comp_direct$glstrinv.real, 2)`     | $p =$ `r round(comp_direct$glstrinv.pval, 4)`     |
| Closeness          | $\Delta_{C} =$ `r round(comp_direct$diffcen.real[[1]], 2)`     | $p =$ `r round(comp_direct$diffcen.pval[[1]], 4)` |
| Betweenness        | $\Delta_{B} =$ `r round(comp_direct$diffcen.real[[2]], 2)`     | $p =$ `r round(comp_direct$diffcen.pval[[2]], 4)` |
| Strength           | $\Delta_{S}^{l} =$ `r round(comp_direct$diffcen.real[[3]], 2)` | $p =$ `r round(comp_direct$diffcen.pval[[3]], 4)` |
| Expected Influence | $\Delta_{EI} =$ `r round(comp_direct$diffcen.real[[4]], 2)`    | $p =$ `r round(comp_direct$diffcen.pval[[4]], 4)` |

: Direct Experience of Fire (`r length(comp_direct$glstrinv.perm)` permutations) {#tbl-comp-1}

| Test               | Statistic                                                        | Significance                                        |
|----------------|-------------------------------|-------------------------|
| Network variance   | $\Delta_{O} =$ `r round(comp_nearmiss$nwinv.real, 2)`            | $p =$ `r round(comp_nearmiss$nwinv.pval, 4)`        |
| Global strength    | $\Delta_{S}^{g} =$ `r round(comp_nearmiss$glstrinv.real, 2)`     | $p =$ `r round(comp_nearmiss$glstrinv.pval, 4)`     |
| Closeness          | $\Delta_{C} =$ `r round(comp_nearmiss$diffcen.real[[1]], 2)`     | $p =$ `r round(comp_nearmiss$diffcen.pval[[1]], 4)` |
| Betweenness        | $\Delta_{B} =$ `r round(comp_nearmiss$diffcen.real[[2]], 2)`     | $p =$ `r round(comp_nearmiss$diffcen.pval[[2]], 4)` |
| Strength           | $\Delta_{S}^{l} =$ `r round(comp_nearmiss$diffcen.real[[3]], 2)` | $p =$ `r round(comp_nearmiss$diffcen.pval[[3]], 4)` |
| Expected Influence | $\Delta_{EI} =$ `r round(comp_nearmiss$diffcen.real[[4]], 2)`    | $p =$ `r round(comp_nearmiss$diffcen.pval[[4]], 4)` |

: Near Miss Experience of Fire (`r length(comp_nearmiss$glstrinv.perm)` permutations) {#tbl-comp-2}

| Test               | Statistic                                                   | Significance                                   |
|----------------|-------------------------------|-------------------------|
| Network variance   | $\Delta_{O} =$ `r round(comp_ems$nwinv.real, 2)`            | $p =$ `r round(comp_ems$nwinv.pval, 4)`        |
| Global strength    | $\Delta_{S}^{g} =$ `r round(comp_ems$glstrinv.real, 2)`     | $p =$ `r round(comp_ems$glstrinv.pval, 4)`     |
| Closeness          | $\Delta_{C} =$ `r round(comp_ems$diffcen.real[[1]], 2)`     | $p =$ `r round(comp_ems$diffcen.pval[[1]], 4)` |
| Betweenness        | $\Delta_{B} =$ `r round(comp_ems$diffcen.real[[2]], 2)`     | $p =$ `r round(comp_ems$diffcen.pval[[2]], 4)` |
| Strength           | $\Delta_{S}^{l} =$ `r round(comp_ems$diffcen.real[[3]], 2)` | $p =$ `r round(comp_ems$diffcen.pval[[3]], 4)` |
| Expected Influence | $\Delta_{EI} =$ `r round(comp_ems$diffcen.real[[4]], 2)`    | $p =$ `r round(comp_ems$diffcen.pval[[4]], 4)` |

: Emergency Services Employment (`r length(comp_ems$glstrinv.perm)` permutations) {#tbl-comp-3}

Network NCT results by substantive control variable
:::

**UPDATE 12/5/2023: Check why EMS Global strength is p = 1, closeness is C = 0 and p = NA. There were some Github discussions about similar problems - is this, too, a bug?**

Direct experience of fire is related to a weak effect on network structure (@tbl-comp-1). Global strength is significantly different, indicating that the overall connectivity has changed between networks. However, network variance is not significantly different. Since the network is dense and non-smallworld, the difference between variance and strength may be due to small changes in many network edges leading to a overall significant change in the sum of edge strength, while leaving individual maximum changes small [see @vanborkulo2022].

Near-miss experiences have a stronger effect on the network structure (@tbl-comp-2). Network variance and global strength are both significantly different, suggesting that a change in overall network structure has occurred. In both cases, the statistic has grown in the network estimated from respondents that have experienced a near miss. In other words: the network seems to be slightly denser in people who have nearly experienced a fire.

Finally, working in emergency services is related to a weak effect on network structure, but inverse to that of a direct fire experience (@tbl-comp-3). Network variance is significantly different, indicating that one or more edges have distinctly changed. However, global strength difference is non-significant, suggesting that these changes have not resulted in an overall change in the total edge strength of the network. In other words: working in emergency services is related to a shift in network structure, but not an increase or decrease in density *per se*.

For the Fire node, no changes seem to have occurred in either the near-miss or the EMS employment comparisons. However, for individuals who have a direct fire experience, Expected Influence has dropped significantly. This suggests that the connections between Fire and other nodes has grown slightly more negative. Because the network does not show any negative edges (@fig-comp-graphs-2), this change corresponds to a drop in intensity of positive connections. The Fire node also shows marginally significant changes on closeness and strength in the direct experience comparison. The change in strength mirrors that of the EI change, further suggesting that the centrality of Fire has slightly dropped.

```{r}
#| label: fig-comp-graphs
#| fig-cap: "Gaussian graphical models of risk perception by substantive control variables, compared using network comparison testing"
#| fig-subcap:
#| -  "No direct experience"
#| -  "Direct experience"
#| -  "No near-miss experience"
#| -  "Near-miss experience"
#| -  "Not in EMS employment"
#| -  "In EMS employment"
#| layout: "[[1,1],[1,1],[1,1]]"

qgraph(net_direct_0$graph,
       layout = mds_spline$conf,
       edge.labels = TRUE,
       maximum = 0.5,
       details = TRUE)
text(-1, -1, paste0("N = ",net_direct_0$nPerson))

qgraph(net_direct_1$graph,
       layout = mds_spline$conf,
       edge.labels = TRUE,
       maximum = 0.5,
       details = TRUE)
text(-1, -1, paste0("N = ",net_direct_1$nPerson))

qgraph(net_nearmiss_0$graph,
       layout = mds_spline$conf,
       edge.labels = TRUE,
       maximum = 0.5,
       details = TRUE)
text(-1, -1, paste0("N = ",net_nearmiss_0$nPerson))

qgraph(net_nearmiss_1$graph,
       layout = mds_spline$conf,
       edge.labels = TRUE,
       maximum = 0.5,
       details = TRUE)
text(-1, -1, paste0("N = ",net_nearmiss_1$nPerson))

qgraph(net_ems_0$graph,
       layout = mds_spline$conf,
       edge.labels = TRUE,
       maximum = 0.5,
       details = TRUE)
text(-1, -1, paste0("N = ",net_ems_0$nPerson))

qgraph(net_ems_1$graph,
       layout = mds_spline$conf,
       edge.labels = TRUE,
       maximum = 0.5,
       details = TRUE)
text(-1, -1, paste0("N = ",net_ems_1$nPerson))

```

# Discussion

To repeat from @sec-hypotheses, we had six hypotheses, grouped into system and node level hypotheses. Both groups of hypotheses state the same:

-   System level:

    -   $H_1^S:$ Experiencing a fire leads to a sparser risk perception network
    -   $H_2^S:$ Experiencing a near-miss leads to a denser risk perception network
    -   $H_3^S:$ Working in emergency services leads to a sparser risk perception

-   Node level:

    -   $H_1^N:$ Experiencing a fire leads to a decrease in the centrality of fire in the risk perception network
    -   $H_2^N:$ Experiencing a near-miss leads to an increase in the centrality of fire in the risk perception network
    -   $H_3^N:$ Working in emergency services leads to a decrease in the centrality of fire in the risk perception network

On the system level, we found no support for $H_1^S$ or $H_3^S$. In both cases, we even found partial support for the opposite direction: for both direct experiences and working in EMS, networks partially have grown more dense than for others.

However, we found strong support for $H_2^S$, that a near-miss experience leads to a denser risk perception network.

*UPDATE 12/5/2023: What does it mean for the node to drop in centrality, viz. the idea that experience lowers System II intensity? Is increased centrality == increased intensity, or is it the other way around?*

On the node level, the situation is very different. Overall, we found very little support for our hypotheses. We found marginal support for $H_1^N$: subjectively experienced probabilities of fire might become less central in the overall network after experiencing a near-miss experience. All other changes were non-significant.

# References {#sec-references}

::: refs
:::
